{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Second-order Attention Network for\n",
    "# Single Image Super-Resolution\n",
    "\n",
    "\n",
    "This version is for PRESENTATION PURPOSES ONLY. All imports have been removed to decrease Binder loading duration and the code does not work.\n",
    "\n",
    "Refer to [Presentation.ipynb](https://github.com/umd-fire-coml/2020-summer-t2-image-super-resolution/blob/master/SAN/TestCode/code/Presentation.ipynb) or its [Binder Presentation](https://mybinder.org/v2/gh/umd-fire-coml/2020-summer-t2-image-super-resolution/master?filepath=SAN%2FTestCode%2Fcode%2FPresentation.ipynb) for the working code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Single Image Super-Resolution (SISR)?\n",
    "The purpose of SISR is to produce a visually high-resolution (HR) output from a low-resolution (LR) input. \n",
    "\n",
    "<table align=\"center\"><tr>\n",
    "    <td><figure>\n",
    "        <img src='resources/baboon_LR.png' height=\"300\" width = \"300\">\n",
    "        <p align = \"center\" style=\"font-size: 20px\">LR Input</p>\n",
    "    </figure>\n",
    "    <td><figure>\n",
    "        <img src='resources/baboon_SR.png' height=\"300\" width = \"300\">\n",
    "        <p align = \"center\" style=\"font-size: 20px\">HR Output</p>\n",
    "    </figure></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Deep convolutional neural networks (CNNs) have been widely explored in SISR. However, most CNN-based SR models focus mainly on designing a deeper or wider network to learn more discriminative high-level features. The inherent feature correlations in intermediate layers are rarely exploited, thus hindering the representational ability of CNNs$.^{[1]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this project, a second-order attention network (SAN) is used for more powerful feature expression and feature correlation. \n",
    "\n",
    "<img src='resources/framework.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "005e31af-02eb-4623-a137-06cab5749c64"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# RUN. NOT SHOWN IN PRESENTATION.\n",
    "\n",
    "class timer():\n",
    "    def __init__(self):\n",
    "        self.acc = 0\n",
    "        self.tic()\n",
    "\n",
    "    def tic(self):\n",
    "        self.t0 = time.time()\n",
    "\n",
    "    def toc(self):\n",
    "        return time.time() - self.t0\n",
    "\n",
    "    def hold(self):\n",
    "        self.acc += self.toc()\n",
    "\n",
    "    def release(self):\n",
    "        ret = self.acc\n",
    "        self.acc = 0\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def reset(self):\n",
    "        self.acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-Locally Enhanced Residual Group (NLRG) Structure\n",
    "\n",
    "SAN uses a NLRG structure, which not only incorporates non-local operations to capture long-distance spatial contextual information, but also contains repeated local-source residual attention groups (LSRAG) to learn increasingly abstract feature representations. Essentially, the inherent feature correlations in intermediate layers are exploited to greatly enhance the representational ability of CNNs$.^{[2]}$\n",
    "\n",
    "<img src='resources/NLRG.png' align=\"center\">\n",
    "\n",
    "The following code excerpts are the most important components of the SAN from 'model/san.py'. They are shown for instructional purposes and are not directly called in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Region-Level Non-Local (RL-NL) module\n",
    "\n",
    "The first part of the NLRG structure is the RN-NL module. Input features are divided into blocks then processed. Feature representation is enhanced before being passed to subsequent layers via exploiting spatial correlations$.^{[2]}$\n",
    "\n",
    "<img src='resources/RL-NL.png' align=\"Center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Non_Local Module (RL-NL)\n",
    "# DO NOT RUN\n",
    "\n",
    "class _NonLocalBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=3, mode='embedded_gaussian',\n",
    "                 sub_sample=True, bn_layer=True):\n",
    "        super(_NonLocalBlockND, self).__init__()\n",
    "        assert dimension in [1, 2, 3]\n",
    "        assert mode in ['embedded_gaussian', 'gaussian', 'dot_product', 'concatenation']\n",
    "\n",
    "        # print('Dimension: %d, mode: %s' % (dimension, mode))\n",
    "\n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool = nn.MaxPool3d\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool = nn.MaxPool2d\n",
    "            sub_sample = nn.Upsample\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool = nn.MaxPool1d\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(self.in_channels)\n",
    "            )\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.constant_(self.W.weight, 0)\n",
    "            nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "        self.theta = None\n",
    "        self.phi = None\n",
    "        self.concat_project = None\n",
    "        # self.fc = nn.Linear(64,2304,bias=True)\n",
    "        # self.sub_bilinear = nn.Upsample(size=(48,48),mode='bilinear')\n",
    "        # self.sub_maxpool = nn.AdaptiveMaxPool2d(output_size=(48,48))\n",
    "        if mode in ['embedded_gaussian', 'dot_product', 'concatenation']:\n",
    "            self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                                 kernel_size=1, stride=1, padding=0)\n",
    "            self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "            if mode == 'embedded_gaussian':\n",
    "                self.operation_function = self._embedded_gaussian\n",
    "            elif mode == 'dot_product':\n",
    "                self.operation_function = self._dot_product\n",
    "            elif mode == 'concatenation':\n",
    "                self.operation_function = self._concatenation\n",
    "                self.concat_project = nn.Sequential(\n",
    "                    nn.Conv2d(self.inter_channels * 2, 1, 1, 1, 0, bias=False),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "        elif mode == 'gaussian':\n",
    "            self.operation_function = self._gaussian\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool(kernel_size=2))\n",
    "            if self.phi is None:\n",
    "                self.phi = max_pool(kernel_size=2)\n",
    "            else:\n",
    "                self.phi = nn.Sequential(self.phi, max_pool(kernel_size=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        output = self.operation_function(x)\n",
    "        return output\n",
    "\n",
    "    def _embedded_gaussian(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "\n",
    "        # x_sub = self.sub_bilinear(x) # bilinear downsample\n",
    "        # x_sub = self.sub_maxpool(x) # maxpool downsample\n",
    "\n",
    "        ##\n",
    "        # g_x = x.view(batch_size, self.inter_channels, -1)\n",
    "        # g_x = g_x.permute(0, 2, 1)\n",
    "        #\n",
    "        # # theta=>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, thw, 0.5c)\n",
    "        # # phi  =>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, 0.5c, thw)\n",
    "        # # f=>(b, thw, 0.5c)dot(b, 0.5c, twh) = (b, thw, thw)\n",
    "        # theta_x = x.view(batch_size, self.inter_channels, -1)\n",
    "        # theta_x = theta_x.permute(0, 2, 1)\n",
    "        # fc = self.fc(theta_x)\n",
    "        # # phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        # # f = torch.matmul(theta_x, phi_x)\n",
    "        # # return f\n",
    "        # # f_div_C = F.softmax(fc, dim=-1)\n",
    "        # return fc\n",
    "\n",
    "        ##\n",
    "        # g=>(b, c, t, h, w)->(b, 0.5c, t, h, w)->(b, thw, 0.5c)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        # theta=>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, thw, 0.5c)\n",
    "        # phi  =>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, 0.5c, thw)\n",
    "        # f=>(b, thw, 0.5c)dot(b, 0.5c, twh) = (b, thw, thw)\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        # return f\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "        # return f_div_C\n",
    "        # (b, thw, thw)dot(b, thw, 0.5c) = (b, thw, 0.5c)->(b, 0.5c, t, h, w)->(b, c, t, h, w)\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "    def _gaussian(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = x.view(batch_size, self.in_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "\n",
    "        if self.sub_sample:\n",
    "            phi_x = self.phi(x).view(batch_size, self.in_channels, -1)\n",
    "        else:\n",
    "            phi_x = x.view(batch_size, self.in_channels, -1)\n",
    "\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "    def _dot_product(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        N = f.size(-1)\n",
    "        f_div_C = f / N\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "    def _concatenation(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        # (b, c, N, 1)\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1, 1)\n",
    "        # (b, c, 1, N)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, 1, -1)\n",
    "\n",
    "        h = theta_x.size(2)\n",
    "        w = phi_x.size(3)\n",
    "        theta_x = theta_x.repeat(1, 1, 1, w)\n",
    "        phi_x = phi_x.repeat(1, 1, h, 1)\n",
    "\n",
    "        concat_feature = torch.cat([theta_x, phi_x], dim=1)\n",
    "        f = self.concat_project(concat_feature)\n",
    "        b, _, h, w = f.size()\n",
    "        f = f.view(b, h, w)\n",
    "\n",
    "        N = f.size(-1)\n",
    "        f_div_C = f / N\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Local-source Residual Attention Group (LSRAG)\n",
    "\n",
    "Simplified blocks are stacked to form LSRAGs, where layers are applied on each block to focus on more informative features. The SOCA mechanism, explored in the next slide, is embedded at the end of each LSRAG$.^{[2]}$\n",
    "\n",
    "<img src='resources/LSRAG.png' align = \"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Local-source Residual Attention Group (LSRARG)\n",
    "# DO NOT RUN\n",
    "\n",
    "class LSRAG(nn.Module):\n",
    "    def __init__(self, conv, n_feat, kernel_size, reduction, act, res_scale, n_resblocks):\n",
    "        super(LSRAG, self).__init__()\n",
    "        ##\n",
    "        self.rcab= nn.ModuleList([RB(conv, n_feat, kernel_size, reduction, \\\n",
    "                                       bias=True, bn=False, act=nn.ReLU(inplace=True), res_scale=1) for _ in range(n_resblocks)])\n",
    "        self.soca = (SOCA(n_feat,reduction=reduction))\n",
    "        self.conv_last = (conv(n_feat, n_feat, kernel_size))\n",
    "        self.n_resblocks = n_resblocks\n",
    "        ##\n",
    "        # modules_body = []\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        # self.gamma = 0.2\n",
    "        # for i in range(n_resblocks):\n",
    "        #     modules_body.append(RCAB(conv, n_feat, kernel_size, reduction, bias=True, bn=False, act=nn.ReLU(inplace=True), res_scale=1))\n",
    "        # modules_body.append(SOCA(n_feat,reduction=reduction))\n",
    "        # # modules_body.append(Nonlocal_CA(in_feat=n_feat, inter_feat=n_feat//8, reduction =reduction, sub_sample=False, bn_layer=False))\n",
    "        # modules_body.append(conv(n_feat, n_feat, kernel_size))\n",
    "        # self.body = nn.Sequential(*modules_body)\n",
    "        ##\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block)\n",
    "        return nn.ModuleList(layers)\n",
    "        # return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # batch_size,C,H,W = x.shape\n",
    "        # y_pre = self.body(x)\n",
    "        # y_pre = y_pre + x\n",
    "        # return y_pre\n",
    "\n",
    "        ## share-source skip connection\n",
    "\n",
    "        for i,l in enumerate(self.rcab):\n",
    "            # x = l(x) + self.gamma*residual\n",
    "            x = l(x)\n",
    "        x = self.soca(x)\n",
    "        x = self.conv_last(x)\n",
    "\n",
    "        x = x + residual\n",
    "\n",
    "        return x\n",
    "        ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Second-Order Channel Attention (SOCA) Mechanism\n",
    "\n",
    "This adaptively rescales the channel-wise features by using second-order feature statistics for more discriminative representations. It learns feature interdependencies by considering second-order statistics of features, which are more helpful for discriminative represenations in CNNs$.^{[2]}$\n",
    "\n",
    "<img src='resources/SOCA.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Second-Order Channel Attention (SOCA)\n",
    "# DO NOT RUN\n",
    "\n",
    "class SOCA(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super(SOCA, self).__init__()\n",
    "        # global average pooling: feature --> point\n",
    "        # self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # feature channel downscale and upscale --> channel weight\n",
    "        self.conv_du = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "            # nn.BatchNorm2d(channel)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, h, w = x.shape  # x: NxCxHxW\n",
    "        N = int(h * w)\n",
    "        min_h = min(h, w)\n",
    "        h1 = 1000\n",
    "        w1 = 1000\n",
    "        if h < h1 and w < w1:\n",
    "            x_sub = x\n",
    "        elif h < h1 and w > w1:\n",
    "            # H = (h - h1) // 2\n",
    "            W = (w - w1) // 2\n",
    "            x_sub = x[:, :, :, W:(W + w1)]\n",
    "        elif w < w1 and h > h1:\n",
    "            H = (h - h1) // 2\n",
    "            # W = (w - w1) // 2\n",
    "            x_sub = x[:, :, H:H + h1, :]\n",
    "        else:\n",
    "            H = (h - h1) // 2\n",
    "            W = (w - w1) // 2\n",
    "            x_sub = x[:, :, H:(H + h1), W:(W + w1)]\n",
    "        # subsample\n",
    "        # subsample_scale = 2\n",
    "        # subsample = nn.Upsample(size=(h // subsample_scale, w // subsample_scale), mode='nearest')\n",
    "        # x_sub = subsample(x)\n",
    "        # max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # max_pool = nn.AvgPool2d(kernel_size=2)\n",
    "        # x_sub = self.max_pool(x)\n",
    "        ##\n",
    "        ## MPN-COV\n",
    "        cov_mat = MPNCOV.CovpoolLayer(x_sub) # Global Covariance pooling layer\n",
    "        cov_mat_sqrt = MPNCOV.SqrtmLayer(cov_mat,5) # Matrix square root layer( including pre-norm,Newton-Schulz iter. and post-com. with 5 iteration)\n",
    "        ##\n",
    "        cov_mat_sum = torch.mean(cov_mat_sqrt,1)\n",
    "        cov_mat_sum = cov_mat_sum.view(batch_size,C,1,1)\n",
    "        # y_ave = self.avg_pool(x)\n",
    "        # y_max = self.max_pool(x)\n",
    "        y_cov = self.conv_du(cov_mat_sum)\n",
    "        # y_max = self.conv_du(y_max)\n",
    "        # y = y_ave + y_max\n",
    "        # expand y to C*H*W\n",
    "        # expand_y = y.expand(-1,-1,h,w)\n",
    "        return y_cov*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='resources/NLRG.png' align=\"center\">\n",
    "In the assembled NLRG, the input first runs through a RL-NL module to enhance feature correlations. \n",
    "\n",
    "Then, it passes through the share-source residual group (SSRG), which consists of a series of LSRAGs with SOCA mechanisms. The SSRG focuses on informative features and learns feature interdependencies based on second-order statistics. The data at the end of the LSRAG/SOCA chain is passed through a convolutional layer.\n",
    "\n",
    "Finally, the data is processed by another RL-NL module and becomes the final output of the NLRG$.^{[2]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='resources/SAN.png' align=\"center\">\n",
    "In the full SAN, a convolutional layer is applied to the LR input before it is passed to the NLRG. Long distance spatial contextual and low frequency information are captured, greatly enhancing the representational potential of the data in CNNs. Then, the data is passed to a CNN upscale module and convoluted to produce the HR output$.^{[2]}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Second-order Channel Attention Network (SAN)\n",
    "# DO NOT RUN\n",
    "class SAN(nn.Module):\n",
    "    def __init__(self, args, conv=common.default_conv):\n",
    "        super(SAN, self).__init__()\n",
    "        n_resgroups = args.n_resgroups\n",
    "        n_resblocks = args.n_resblocks\n",
    "        n_feats = args.n_feats\n",
    "        kernel_size = 3\n",
    "        reduction = args.reduction \n",
    "        scale = args.scale[0]\n",
    "        act = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # RGB mean for DIV2K\n",
    "        rgb_mean = (0.4488, 0.4371, 0.4040)\n",
    "        rgb_std = (1.0, 1.0, 1.0)\n",
    "        self.sub_mean = common.MeanShift(args.rgb_range, rgb_mean, rgb_std)\n",
    "        # self.soca= SOCA(n_feats, reduction=reduction)\n",
    "\n",
    "        # define head module\n",
    "        modules_head = [conv(args.n_colors, n_feats, kernel_size)]\n",
    "\n",
    "        # define body module\n",
    "        ## share-source skip connection\n",
    "\n",
    "        ##\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        # self.gamma = 0.2\n",
    "        self.n_resgroups = n_resgroups\n",
    "        self.RG = nn.ModuleList([LSRAG(conv, n_feats, kernel_size, reduction, \\\n",
    "                                              act=act, res_scale=args.res_scale, n_resblocks=n_resblocks) for _ in range(n_resgroups)])\n",
    "        self.conv_last = conv(n_feats, n_feats, kernel_size)\n",
    "\n",
    "        # modules_body = [\n",
    "        #     ResidualGroup(\n",
    "        #         conv, n_feats, kernel_size, reduction, act=act, res_scale=args.res_scale, n_resblocks=n_resblocks) \\\n",
    "        #     for _ in range(n_resgroups)]\n",
    "        # modules_body.append(conv(n_feats, n_feats, kernel_size))\n",
    "\n",
    "\n",
    "        # define tail module\n",
    "        modules_tail = [\n",
    "            common.Upsampler(conv, scale, n_feats, act=False),\n",
    "            conv(n_feats, args.n_colors, kernel_size)]\n",
    "\n",
    "        self.add_mean = common.MeanShift(args.rgb_range, rgb_mean, rgb_std, 1)\n",
    "        self.non_local = Nonlocal_CA(in_feat=n_feats, inter_feat=n_feats//8, reduction=8,sub_sample=False, bn_layer=False)\n",
    "\n",
    "\n",
    "        self.head = nn.Sequential(*modules_head)\n",
    "        # self.body = nn.Sequential(*modules_body)\n",
    "        self.tail = nn.Sequential(*modules_tail)\n",
    "\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block)\n",
    "\n",
    "        return nn.ModuleList(layers)\n",
    "        # return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sub_mean(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        ## add nonlocal\n",
    "        xx = self.non_local(x)\n",
    "\n",
    "        # share-source skip connection\n",
    "        residual = xx\n",
    "\n",
    "        # res = self.RG(xx)\n",
    "        # res = res + xx\n",
    "        ## share-source residual gruop\n",
    "        for i,l in enumerate(self.RG):\n",
    "            xx = l(xx) + self.gamma*residual\n",
    "            # xx = self.gamma*xx + residual\n",
    "        # body part\n",
    "        # res = self.body(xx)\n",
    "        ##\n",
    "        ## add nonlocal\n",
    "        res = self.non_local(xx)\n",
    "        ##\n",
    "        # res = self.soca(res)\n",
    "        # res += x\n",
    "        res = res + x\n",
    "\n",
    "        x = self.tail(res)\n",
    "        x = self.add_mean(x)\n",
    "\n",
    "        return x \n",
    "\n",
    "    def load_state_dict(self, state_dict, strict=False):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name in own_state:\n",
    "                if isinstance(param, nn.Parameter):\n",
    "                    param = param.data\n",
    "                try:\n",
    "                    own_state[name].copy_(param)\n",
    "                except Exception:\n",
    "                    if name.find('tail') >= 0:\n",
    "                        print('Replace pre-trained upsampler to new one...')\n",
    "                    else:\n",
    "                        raise RuntimeError('While copying the parameter named {}, '\n",
    "                                           'whose dimensions in the model are {} and '\n",
    "                                           'whose dimensions in the checkpoint are {}.'\n",
    "                                           .format(name, own_state[name].size(), param.size()))\n",
    "            elif strict:\n",
    "                if name.find('tail') == -1:\n",
    "                    raise KeyError('unexpected key \"{}\" in state_dict'\n",
    "                                   .format(name))\n",
    "\n",
    "        if strict:\n",
    "            missing = set(own_state.keys()) - set(state_dict.keys())\n",
    "            if len(missing) > 0:\n",
    "                raise KeyError('missing keys in state_dict: \"{}\"'.format(missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Back to the test code. This SAN model is trained with the DIV2K dataset, a collection of 900 HR and LR image pairs. Training takes hours, so we have already pretrained a model that SRs x2 scale LR images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "44a9686b-7e30-48bc-bdd3-759c722aa808"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# RUN. NOT SHOWN IN PRESENTATION.\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, args, loader, my_model, my_loss, ckp):\n",
    "        self.args = args\n",
    "        self.scale = args.scale\n",
    "\n",
    "        self.ckp = ckp\n",
    "        self.loader_train = loader.loader_train\n",
    "        self.loader_test = loader.loader_test\n",
    "        self.model = my_model\n",
    "        self.loss = my_loss\n",
    "        self.optimizer = make_optimizer(args, self.model)\n",
    "        self.scheduler = make_scheduler(args, self.optimizer)\n",
    "\n",
    "        if self.args.load != '.':\n",
    "            self.optimizer.load_state_dict(\n",
    "                torch.load(os.path.join(ckp.dir, 'optimizer.pt'))\n",
    "            )\n",
    "            for _ in range(len(ckp.log)): self.scheduler.step()\n",
    "\n",
    "        self.error_last = 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "44a9686b-7e30-48bc-bdd3-759c722aa808"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(Trainer):\n",
    "    def train(self):\n",
    "        self.scheduler.step()\n",
    "        self.loss.step()\n",
    "        epoch = self.scheduler.last_epoch + 1\n",
    "        lr = self.scheduler.get_lr()[0]\n",
    "\n",
    "        self.ckp.write_log(\n",
    "            '[Epoch {}]\\tLearning rate: {:.2e}'.format(epoch, Decimal(lr))\n",
    "        )\n",
    "        self.loss.start_log()\n",
    "        self.model.train()\n",
    "\n",
    "        timer_data, timer_model = timer(), timer()\n",
    "        for batch, (lr, hr, _, idx_scale) in enumerate(self.loader_train):\n",
    "            lr, hr = self.prepare([lr, hr])\n",
    "            timer_data.hold()\n",
    "            timer_model.tic()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            sr = self.model(lr, idx_scale)\n",
    "            loss = self.loss(sr, hr)\n",
    "            if loss.item() < self.args.skip_threshold * self.error_last:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            else:\n",
    "                print('Skip this batch {}! (Loss: {})'.format(\n",
    "                    batch + 1, loss.item()\n",
    "                ))\n",
    "\n",
    "            timer_model.hold()\n",
    "\n",
    "            if (batch + 1) % self.args.print_every == 0:\n",
    "                self.ckp.write_log('[{}/{}]\\t{}\\t{:.1f}+{:.1f}s'.format(\n",
    "                    (batch + 1) * self.args.batch_size,\n",
    "                    len(self.loader_train.dataset),\n",
    "                    self.loss.display_loss(batch),\n",
    "                    timer_model.release(),\n",
    "                    timer_data.release()))\n",
    "\n",
    "            timer_data.tic()\n",
    "\n",
    "        self.loss.end_log(len(self.loader_train))\n",
    "        self.error_last = self.loss.log[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "44a9686b-7e30-48bc-bdd3-759c722aa808"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(Trainer):\n",
    "    def test(self):\n",
    "        epoch = self.scheduler.last_epoch + 1\n",
    "        self.ckp.write_log('\\nEvaluation:')\n",
    "        self.ckp.add_log(torch.zeros(1, len(self.scale)))\n",
    "        self.model.eval()\n",
    "\n",
    "        timer_test = timer()\n",
    "        with torch.no_grad():\n",
    "            for idx_scale, scale in enumerate(self.scale):\n",
    "                eval_acc = 0\n",
    "                self.loader_test.dataset.set_scale(idx_scale)\n",
    "                tqdm_test = tqdm(self.loader_test, ncols=80)\n",
    "                for idx_img, (lr, hr, filename) in enumerate(tqdm_test):\n",
    "                    filename = filename[0]\n",
    "                    no_eval = (hr.nelement() == 1)\n",
    "                    if not no_eval:\n",
    "                        lr, hr = self.prepare([lr, hr])\n",
    "                    else:\n",
    "                        lr = self.prepare([lr])[0]\n",
    "\n",
    "                    sr = self.model(lr, idx_scale)\n",
    "                    sr = quantize(sr, self.args.rgb_range)\n",
    "\n",
    "                    save_list = [sr]\n",
    "                    if not no_eval:\n",
    "                        eval_acc += calc_psnr(\n",
    "                            sr, hr, scale, self.args.rgb_range,\n",
    "                            benchmark=self.loader_test.dataset.benchmark\n",
    "                        )\n",
    "                        save_list.extend([lr, hr])\n",
    "\n",
    "                    if self.args.save_results:\n",
    "                        #self.ckp.save_results(filename, save_list, scale)\n",
    "                        self.ckp.save_results_nopostfix(filename, save_list, scale)\n",
    "\n",
    "                self.ckp.log[-1, idx_scale] = eval_acc / len(self.loader_test)\n",
    "                best = self.ckp.log.max(0)\n",
    "                self.ckp.write_log(\n",
    "                    '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
    "                        self.args.data_test,\n",
    "                        scale,\n",
    "                        self.ckp.log[-1, idx_scale],\n",
    "                        best[0][idx_scale],\n",
    "                        best[1][idx_scale] + 1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        self.ckp.write_log(\n",
    "            'Total time: {:.2f}s, ave time: {:.2f}s\\n'.format(timer_test.toc(), timer_test.toc()/len(self.loader_test)), refresh=True\n",
    "        )\n",
    "        if not self.args.test_only:\n",
    "            self.ckp.save(self, epoch, is_best=(best[1][0] + 1 == epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "44a9686b-7e30-48bc-bdd3-759c722aa808"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# RUN. NOT SHOWN IN PRESENTATION.\n",
    "\n",
    "class Trainer(Trainer):\n",
    "    def prepare(self, l, volatile=False):\n",
    "        device = torch.device('cpu' if self.args.cpu else 'cuda')\n",
    "        def _prepare(tensor):\n",
    "            if self.args.precision == 'half': tensor = tensor.half()\n",
    "            return tensor.to(device)\n",
    "           \n",
    "        return [_prepare(_l) for _l in l]\n",
    "\n",
    "    def terminate(self):\n",
    "        if self.args.test_only:\n",
    "            self.test()\n",
    "            return True\n",
    "        else:\n",
    "            epoch = self.scheduler.last_epoch + 1\n",
    "            return epoch >= self.args.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "LR datasets are stored in the directory '../LR/LRBI.' This SAN SISR program opens those datasets, super-resolutions the images in them, then saves the SR output in the directory '../SR/BI' with configuration and log .txt files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "055b4053-bf3a-4372-bd07-f2a4f2dd0f4e"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class checkpoint():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.ok = True\n",
    "        self.log = torch.Tensor()\n",
    "        now = datetime.datetime.now().strftime('%Y-%m-%d-%H:%M:%S')\n",
    "\n",
    "        if args.load == '.':\n",
    "            if args.save == '.': args.save = now\n",
    "            self.dir = '../SR/' + args.degradation + '/' + args.save\n",
    "        else:\n",
    "            self.dir = '../experiment/' + args.load\n",
    "            if not os.path.exists(self.dir):\n",
    "                args.load = '.'\n",
    "            else:\n",
    "                self.log = torch.load(self.dir + '/psnr_log.pt')\n",
    "                print('Continue from epoch {}...'.format(len(self.log)))\n",
    "\n",
    "        if args.reset:\n",
    "            os.system('rm -rf ' + self.dir)\n",
    "            args.load = '.'\n",
    "\n",
    "        def _make_dir(path):\n",
    "            if not os.path.exists(path): os.makedirs(path)\n",
    "\n",
    "        _make_dir(self.dir)\n",
    "        \n",
    "        _make_dir(self.dir + '/' + args.testset + '/x' + str(args.scale[0]))\n",
    "\n",
    "        open_type = 'a' if os.path.exists(self.dir + '/log.txt') else 'w'\n",
    "        self.log_file = open(self.dir + '/log.txt', open_type)\n",
    "        with open(self.dir + '/config.txt', open_type) as f:\n",
    "            f.write(now + '\\n\\n')\n",
    "            for arg in vars(args):\n",
    "                f.write('{}: {}\\n'.format(arg, getattr(args, arg)))\n",
    "            f.write('\\n')\n",
    "\n",
    "    def save(self, trainer, epoch, is_best=False):\n",
    "        trainer.model.save(self.dir, epoch, is_best=is_best)\n",
    "        trainer.loss.save(self.dir)\n",
    "        trainer.loss.plot_loss(self.dir, epoch)\n",
    "\n",
    "        self.plot_psnr(epoch)\n",
    "        torch.save(self.log, os.path.join(self.dir, 'psnr_log.pt'))\n",
    "        torch.save(\n",
    "            trainer.optimizer.state_dict(),\n",
    "            os.path.join(self.dir, 'optimizer.pt')\n",
    "        )\n",
    "\n",
    "    def add_log(self, log):\n",
    "        self.log = torch.cat([self.log, log])\n",
    "\n",
    "    def write_log(self, log, refresh=False):\n",
    "        print(log)\n",
    "        self.log_file.write(log + '\\n')\n",
    "        if refresh:\n",
    "            self.log_file.close()\n",
    "            self.log_file = open(self.dir + '/log.txt', 'a')\n",
    "\n",
    "    def done(self):\n",
    "        self.log_file.close()\n",
    "\n",
    "    def plot_psnr(self, epoch):\n",
    "        axis = np.linspace(1, epoch, epoch)\n",
    "        label = 'SR on {}'.format(self.args.data_test)\n",
    "        fig = plt.figure()\n",
    "        plt.title(label)\n",
    "        for idx_scale, scale in enumerate(self.args.scale):\n",
    "            plt.plot(\n",
    "                axis,\n",
    "                self.log[:, idx_scale].numpy(),\n",
    "                label='Scale {}'.format(scale)\n",
    "            )\n",
    "        plt.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('PSNR')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('{}/test_{}.pdf'.format(self.dir, self.args.data_test))\n",
    "        plt.close(fig)\n",
    "\n",
    "    def save_results(self, filename, save_list, scale):\n",
    "        filename = '{}/results/{}_x{}_'.format(self.dir, filename, scale)\n",
    "        postfix = ('SR', 'LR', 'HR')\n",
    "        for v, p in zip(save_list, postfix):\n",
    "            normalized = v[0].data.mul(255 / self.args.rgb_range)\n",
    "            ndarr = normalized.byte().permute(1, 2, 0).cpu().numpy()\n",
    "            imageio.imsave('{}{}.png'.format(filename, p), ndarr)\n",
    "\n",
    "    def save_results_nopostfix(self, filename, save_list, scale):\n",
    "        #print(filename)\n",
    "        if self.args.degradation == 'BI':\n",
    "            filename = filename.replace(\"LRBI\", self.args.save)\n",
    "        elif self.args.degradation == 'BD':\n",
    "            filename = filename.replace(\"LRBD\", self.args.save)\n",
    "        \n",
    "        filename = '{}/{}/x{}/{}'.format(self.dir, self.args.testset, scale, filename)\n",
    "        postfix = ('SR', 'LR', 'HR')\n",
    "        for v, p in zip(save_list, postfix):\n",
    "            normalized = v[0].data.mul(255 / self.args.rgb_range)\n",
    "            ndarr = normalized.byte().permute(1, 2, 0).cpu().numpy()\n",
    "            imageio.imsave('{}.png'.format(filename), ndarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "055b4053-bf3a-4372-bd07-f2a4f2dd0f4e"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def quantize(img, rgb_range):\n",
    "    pixel_range = 255 / rgb_range\n",
    "    return img.mul(pixel_range).clamp(0, 255).round().div(pixel_range)\n",
    "\n",
    "def calc_psnr(sr, hr, scale, rgb_range, benchmark=False):\n",
    "    diff = (sr - hr).data.div(rgb_range)\n",
    "    '''\n",
    "    if benchmark:\n",
    "        shave = scale\n",
    "        if diff.size(1) > 1:\n",
    "            convert = diff.new(1, 3, 1, 1)\n",
    "            convert[0, 0, 0, 0] = 65.738\n",
    "            convert[0, 1, 0, 0] = 129.057\n",
    "            convert[0, 2, 0, 0] = 25.064\n",
    "            diff.mul_(convert).div_(256)\n",
    "            diff = diff.sum(dim=1, keepdim=True)\n",
    "    else:\n",
    "        shave = scale + 6\n",
    "    '''\n",
    "    shave = scale\n",
    "    if diff.size(1) > 1:\n",
    "        convert = diff.new(1, 3, 1, 1)\n",
    "        convert[0, 0, 0, 0] = 65.738\n",
    "        convert[0, 1, 0, 0] = 129.057\n",
    "        convert[0, 2, 0, 0] = 25.064\n",
    "        diff.mul_(convert).div_(256)\n",
    "        diff = diff.sum(dim=1, keepdim=True)\n",
    "\n",
    "    valid = diff[:, :, shave:-shave, shave:-shave]\n",
    "    mse = valid.pow(2).mean()\n",
    "\n",
    "    return -10 * math.log10(mse)\n",
    "\n",
    "def make_optimizer(args, my_model):\n",
    "    trainable = filter(lambda x: x.requires_grad, my_model.parameters())\n",
    "\n",
    "    if args.optimizer == 'SGD':\n",
    "        optimizer_function = optim.SGD\n",
    "        kwargs = {'momentum': args.momentum}\n",
    "    elif args.optimizer == 'ADAM':\n",
    "        optimizer_function = optim.Adam\n",
    "        kwargs = {\n",
    "            'betas': (args.beta1, args.beta2),\n",
    "            'eps': args.epsilon\n",
    "        }\n",
    "    elif args.optimizer == 'RMSprop':\n",
    "        optimizer_function = optim.RMSprop\n",
    "        kwargs = {'eps': args.epsilon}\n",
    "\n",
    "    kwargs['lr'] = args.lr\n",
    "    kwargs['weight_decay'] = args.weight_decay\n",
    "    \n",
    "    return optimizer_function(trainable, **kwargs)\n",
    "\n",
    "def make_scheduler(args, my_optimizer):\n",
    "    if args.decay_type == 'step':\n",
    "        scheduler = lrs.StepLR(\n",
    "            my_optimizer,\n",
    "            step_size=args.lr_decay,\n",
    "            gamma=args.gamma\n",
    "        )\n",
    "    elif args.decay_type.find('step') >= 0:\n",
    "        milestones = args.decay_type.split('_')\n",
    "        milestones.pop(0)\n",
    "        milestones = list(map(lambda x: int(x), milestones))\n",
    "        scheduler = lrs.MultiStepLR(\n",
    "            my_optimizer,\n",
    "            milestones=milestones,\n",
    "            gamma=args.gamma\n",
    "        )\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "11106f52-0d5c-4f65-a4a4-8d060440baae"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--degradation'], dest='degradation', nargs=None, const=None, default='BI', type=<class 'str'>, choices=['BI', 'BD'], help='degradation model: BI, BD', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN. NOT SHOWN IN PRESENTATION.\n",
    "\n",
    "def set_template(args):\n",
    "    # Set the templates here\n",
    "    if args.template.find('jpeg') >= 0:\n",
    "        args.data_train = 'DIV2K_jpeg'\n",
    "        args.data_test = 'DIV2K_jpeg'\n",
    "        args.epochs = 200\n",
    "        args.lr_decay = 100\n",
    "\n",
    "    if args.template.find('EDSR_paper') >= 0:\n",
    "        args.model = 'EDSR'\n",
    "        args.n_resblocks = 32\n",
    "        args.n_feats = 256\n",
    "        args.res_scale = 0.1\n",
    "\n",
    "    if args.template.find('MDSR') >= 0:\n",
    "        args.model = 'MDSR'\n",
    "        args.patch_size = 48\n",
    "        args.epochs = 1650\n",
    "\n",
    "    if args.template.find('DDBPN') >= 0:\n",
    "        args.model = 'DDBPN'\n",
    "        args.patch_size = 128\n",
    "        args.scale = '4'\n",
    "\n",
    "        args.data_test = 'Set5'\n",
    "\n",
    "        args.batch_size = 20\n",
    "        args.epochs = 1000\n",
    "        args.lr_decay = 500\n",
    "        args.gamma = 0.1\n",
    "        args.weight_decay = 1e-4\n",
    "\n",
    "        args.loss = '1*MSE'\n",
    "\n",
    "    if args.template.find('GAN') >= 0:\n",
    "        args.epochs = 200\n",
    "        args.lr = 5e-5\n",
    "        args.lr_decay = 150\n",
    "\n",
    "parser = argparse.ArgumentParser(description='EDSR and MDSR')\n",
    "\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help='Enables debug mode')\n",
    "parser.add_argument('--template', default='.',\n",
    "                    help='You can set various templates in option.py')\n",
    "\n",
    "# Hardware specifications\n",
    "parser.add_argument('--n_threads', type=int, default=1,\n",
    "                    help='number of threads for data loading')\n",
    "parser.add_argument('--cpu', action='store_true',\n",
    "                    help='use cpu only')\n",
    "parser.add_argument('--n_GPUs', type=int, default=1,\n",
    "                    help='number of GPUs')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed')\n",
    "\n",
    "# Data specifications\n",
    "parser.add_argument('--dir_data', type=str, default='../../DIV2K',\n",
    "                    help='dataset directory')\n",
    "parser.add_argument('--dir_demo', type=str, default='../test',\n",
    "                    help='demo image directory')\n",
    "parser.add_argument('--data_train', type=str, default='DIV2K',\n",
    "                    help='train dataset name')\n",
    "parser.add_argument('--data_test', type=str, default='MyImage',\n",
    "                    help='test dataset name')\n",
    "parser.add_argument('--benchmark_noise', action='store_true',\n",
    "                    help='use noisy benchmark sets')\n",
    "parser.add_argument('--n_train', type=int, default=800,\n",
    "                    help='number of training set')\n",
    "parser.add_argument('--n_val', type=int, default=10,\n",
    "                    help='number of validation set')\n",
    "parser.add_argument('--offset_val', type=int, default=800,\n",
    "                    help='validation index offest')\n",
    "parser.add_argument('--ext', type=str, default='sep',\n",
    "                    help='dataset file extension')\n",
    "\n",
    "parser.add_argument('--patch_size', type=int, default=192,\n",
    "                    help='output patch size')\n",
    "parser.add_argument('--rgb_range', type=int, default=255,\n",
    "                    help='maximum value of RGB')\n",
    "parser.add_argument('--n_colors', type=int, default=3,\n",
    "                    help='number of color channels to use')\n",
    "parser.add_argument('--noise', type=str, default='.',\n",
    "                    help='Gaussian noise std.')\n",
    "parser.add_argument('--chop', action='store_true',\n",
    "                    help='enable memory-efficient forward')\n",
    "#\n",
    "parser.add_argument('--extend', type=str, default='.',\n",
    "                    help='pre-trained model directory')\n",
    "\n",
    "parser.add_argument('--res_scale', type=float, default=1,\n",
    "                    help='residual scaling')\n",
    "parser.add_argument('--shift_mean', default=True,\n",
    "                    help='subtract pixel mean from the input')\n",
    "parser.add_argument('--precision', type=str, default='single',\n",
    "                    choices=('single', 'half'),\n",
    "                    help='FP precision for test (single | half)')\n",
    "\n",
    "# Training specifications\n",
    "parser.add_argument('--reset', action='store_true',\n",
    "                    help='reset the training')\n",
    "parser.add_argument('--test_every', type=int, default=1000,\n",
    "                    help='do test per every N batches')\n",
    "parser.add_argument('--epochs', type=int, default=3000,\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                    help='input batch size for training')\n",
    "parser.add_argument('--split_batch', type=int, default=1,\n",
    "                    help='split the batch into smaller chunks')\n",
    "parser.add_argument('--self_ensemble', action='store_true',\n",
    "                    help='use self-ensemble method for test')\n",
    "parser.add_argument('--test_only', action='store_true',\n",
    "                    help='set this option to test the model')\n",
    "parser.add_argument('--gan_k', type=int, default=1,\n",
    "                    help='k value for adversarial loss')\n",
    "\n",
    "# Optimization specifications\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay', type=int, default=200,\n",
    "                    help='learning rate decay per N epochs')\n",
    "parser.add_argument('--decay_type', type=str, default='step',\n",
    "                    help='learning rate decay type')\n",
    "parser.add_argument('--gamma', type=float, default=0.5,\n",
    "                    help='learning rate decay factor for step decay')\n",
    "parser.add_argument('--optimizer', default='ADAM',\n",
    "                    choices=('SGD', 'ADAM', 'RMSprop'),\n",
    "                    help='optimizer to use (SGD | ADAM | RMSprop)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--beta1', type=float, default=0.9,\n",
    "                    help='ADAM beta1')\n",
    "parser.add_argument('--beta2', type=float, default=0.999,\n",
    "                    help='ADAM beta2')\n",
    "parser.add_argument('--epsilon', type=float, default=1e-8,\n",
    "                    help='ADAM epsilon for numerical stability')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "\n",
    "# Loss specifications\n",
    "parser.add_argument('--loss', type=str, default='1*L1',\n",
    "                    help='loss function configuration')\n",
    "parser.add_argument('--skip_threshold', type=float, default='1e6',\n",
    "                    help='skipping batch that has large error')\n",
    "\n",
    "# Log specifications\n",
    "\n",
    "parser.add_argument('--load', type=str, default='.',\n",
    "                    help='file name to load')\n",
    "parser.add_argument('--resume', type=int, default=0,\n",
    "                    help='resume from specific checkpoint')\n",
    "parser.add_argument('--print_model', action='store_true',\n",
    "                    help='print model')\n",
    "parser.add_argument('--save_models', action='store_true',\n",
    "                    help='save all intermediate models')\n",
    "parser.add_argument('--print_every', type=int, default=100,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save_results', action='store_true',\n",
    "                    help='save output results')\n",
    "# New options\n",
    "parser.add_argument('--scale', default='3', choices=['2','3','4','8'],\n",
    "                    help='super resolution scale')\n",
    "parser.add_argument('--save', type=str, default='BIX3_G20R10P48_nonlocal_sub',\n",
    "                    help='file name to save')\n",
    "parser.add_argument('--model', default='rcan_multiscal_nonlocal',\n",
    "                    help='model name')\n",
    "parser.add_argument('--act', type=str, default='relu',\n",
    "                    help='activation function')\n",
    "parser.add_argument('--pre_train', type=str, default='../model/BIX3_G20R10P48_nonlocal_sub/model/model_best.pt',\n",
    "                    help='pre-trained model directory')\n",
    "parser.add_argument('--n_resgroups', type=int, default=20,\n",
    "                    help='number of residual groups')\n",
    "parser.add_argument('--n_resblocks', type=int, default=10,\n",
    "                    help='number of residual blocks')\n",
    "parser.add_argument('--n_feats', type=int, default=64,\n",
    "                    help='number of feature maps')\n",
    "parser.add_argument('--reduction', type=int, default=16,\n",
    "                    help='number of feature maps reduction')\n",
    "\n",
    "parser.add_argument('--testpath', type=str, default='../LR/LRBI',\n",
    "                    help='dataset directory for testing')\n",
    "parser.add_argument('--testset', type=str, default='Manga109', choices =['Set5','Set14','BSD100','Urban100','Manga109'],\n",
    "                    help='dataset name for testing')\n",
    "parser.add_argument('--degradation', type=str, default='BI', choices =['BI','BD'],\n",
    "                    help='degradation model: BI, BD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These are the arguments used to produce SR Set5x2 images from the LR Set5 images in the x2 scale dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "11106f52-0d5c-4f65-a4a4-8d060440baae"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(args = ['--model', 'san', '--data_test', 'MyImage', '--save', 'Set5x2', \n",
    "        '--scale', '2', '--n_resgroups', '20', '--n_resblocks', '10', '--n_feats', '64',\n",
    "        '--reset', '--chop', '--save_results', '--test_only', '--testpath', '../LR/LRBI',\n",
    "        '--testset', 'Set5', '--pre_train', '../model/SAN_BI2X.pt', '--n_threads', '0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The program can also be run with these arguments by executing \"python main.py --model san --data_test MyImage --save Set5x2 --scale 2 --n_resgroups 20 --n_resblocks 10 --n_feats 64 --reset --chop --save_results --test_only --testpath ../LR/LRBI --testset Set5 --pre_train ../model/SAN_BI2X.pt --n_threads 0\" in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "11106f52-0d5c-4f65-a4a4-8d060440baae"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "set_template(args)\n",
    "\n",
    "args.scale = list(map(lambda x: int(x), args.scale.split('+')))\n",
    "\n",
    "if args.epochs == 0:\n",
    "    args.epochs = 1e8\n",
    "\n",
    "for arg in vars(args):\n",
    "    if vars(args)[arg] == 'True':\n",
    "        vars(args)[arg] = True\n",
    "    elif vars(args)[arg] == 'False':\n",
    "        vars(args)[arg] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, run the program in this cell and the SR images will be saved in '../SR/BI/Set5x2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "c13a994d-b759-4646-a1c6-3037edf72cf6"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../model/SAN_BI2X.pt\n",
      "\n",
      "Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:11<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MyImage x2]\tPSNR: 0.000 (Best: 0.000 @epoch 1)\n",
      "Total time: 11.16s, ave time: 2.23s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN THE PROGRAM\n",
    "# SR results in ~/TestCode/SR/BI/SET\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "checkpoint = checkpoint(args)\n",
    "\n",
    "if checkpoint.ok:\n",
    "    loader = data.Data(args)\n",
    "    model = model.Model(args, checkpoint)\n",
    "    loss = loss.Loss(args, checkpoint) if not args.test_only else None\n",
    "    t = Trainer(args, loader, model, loss, checkpoint)\n",
    "    while not t.terminate():\n",
    "        t.train()\n",
    "        t.test()\n",
    "\n",
    "    checkpoint.done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "09225b8d-3179-4513-8357-0c4377f416bc"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "1. Dai, Tao, et al. Daitao/SAN. Second-Order Attention Network for Single Image Super-Resolution (CVPR-2019), GitHub, 15 Aug. 2019, github.com/daitao/SAN.\n",
    "2. Dai, Tao, et al. Second-Order Attention Network for Single Image Super-Resolution. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, doi:10.1109/cvpr.2019.01132."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
